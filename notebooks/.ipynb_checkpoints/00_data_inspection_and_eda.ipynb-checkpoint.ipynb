{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0395535a-bb69-474f-91cf-ca2eb619fa5f",
   "metadata": {},
   "source": [
    "# Comprehensive Data Inspection and EDA for FarmAI Analytics\n",
    "## Project: FarmAI - Smart Crop Disease Detection System\n",
    "\n",
    "\n",
    "**Objective:**\n",
    "This notebook initializes the **FarmAI** project pipeline. Our goal is to inspect the raw **PlantVillage** dataset, verify data integrity, analyze class distributions, and prepare a clean dataset for the Deep Learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb0643-dbfc-4dc9-96e0-d40bba99f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ENVIRONMENT SETUP & IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e197748-35e7-48e0-8e85-41eabd2a2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image # For image handling\n",
    "import json # For saving class indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9eb4bc-3792-4b6b-a43f-78f09b5849ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd().parent\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e1773-fede-43f6-808b-e7eaad77b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36093a31-2542-4d09-97f3-b20f10fae9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import config\n",
    "\n",
    "print(\"✅ Config loaded successfully!\")\n",
    "\n",
    "# Some installs of the `config` module may not expose `get_config_summary`.\n",
    "# Use it if available; otherwise fall back to a safe summary of key attributes.\n",
    "if hasattr(config, \"get_config_summary\"):\n",
    "\ttry:\n",
    "\t\tconfig.get_config_summary()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error calling config.get_config_summary(): {e}\")\n",
    "\t\tprint(\"Falling back to printing a minimal config summary below.\")\n",
    "\t\tfallback_keys = [\n",
    "\t\t\t\"RANDOM_SEED\",\n",
    "\t\t\t\"RAW_DATA_DIR\",\n",
    "\t\t\t\"FIGURES_DIR\",\n",
    "\t\t\t\"PROCESSED_DATA_DIR\",\n",
    "\t\t\t\"METRICS_DIR\",\n",
    "\t\t\t\"IMG_SIZE\",\n",
    "\t\t\t\"NUM_CLASSES_TO_USE\",\n",
    "\t\t]\n",
    "\t\tfor k in fallback_keys:\n",
    "\t\t\tprint(f\"  - {k}: {getattr(config, k, None)}\")\n",
    "else:\n",
    "\tprint(\"get_config_summary() not found in config module. Falling back to printing a minimal config summary:\")\n",
    "\tfallback_keys = [\n",
    "\t\t\"RANDOM_SEED\",\n",
    "\t\t\"RAW_DATA_DIR\",\n",
    "\t\t\"FIGURES_DIR\",\n",
    "\t\t\"PROCESSED_DATA_DIR\",\n",
    "\t\t\"METRICS_DIR\",\n",
    "\t\t\"IMG_SIZE\",\n",
    "\t\t\"NUM_CLASSES_TO_USE\",\n",
    "\t]\n",
    "\tfor k in fallback_keys:\n",
    "\t\tprint(f\"  - {k}: {getattr(config, k, None)}\")\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0412a6-4655-401c-9064-c590522253a7",
   "metadata": {},
   "source": [
    "## Set random seeds for reproducibility\n",
    "np.random.seed(config.RANDOM_SEED)\n",
    "\n",
    "random.seed(config.RANDOM_SEED)\n",
    "\n",
    "tf.random.set_seed(config.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c62797-6bd1-4109-8565-ed732813bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate configuration\n",
    "try:\n",
    "    config.validate_config()\n",
    "    config.get_config_summary()\n",
    "    print(\"Environment and configuration loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error validating configuration: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec7fa6-18f3-4325-bb80-052a53a6c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directories exist\n",
    "config.FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "config.METRICS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b515e752-47c3-45a8-8d83-1be9f68cb1e1",
   "metadata": {},
   "source": [
    "\n",
    "## 2. DATA EXTRACTION & INSPECTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8cfcd-0cd6-4660-810d-7511763f1e17",
   "metadata": {},
   "source": [
    "### 2.1. Load and Verify Dataset Structure\n",
    "\n",
    "We are loading the raw image data from the local directory. This step ensures that the dataset path is correct and maps out all available crop disease classes that **FarmAI** will learn to detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21b7b4-4699-40ba-9ebc-3751feb1c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = config.RAW_DATA_DIR\n",
    "\n",
    "if not raw_data_path.exists():\n",
    "    print(f\"Error: Raw data directory not found at {raw_data_path}\")\n",
    "    print(\"Action: Please download the PlantVillage dataset and place the 'color' folder inside 'data/raw/plantvillage/'.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# List all class directories\n",
    "class_dirs = [d for d in raw_data_path.iterdir() if d.is_dir()]\n",
    "all_class_names = sorted([d.name for d in class_dirs])\n",
    "\n",
    "# Select a subset of classes for this analysis, as specified in config.\n",
    "# This makes the notebook run faster for demonstration purposes.\n",
    "if config.NUM_CLASSES_TO_USE and config.NUM_CLASSES_TO_USE < len(all_class_names):\n",
    "    selected_class_names = random.sample(all_class_names, config.NUM_CLASSES_TO_USE)\n",
    "    selected_class_names = sorted(selected_class_names) # Keep consistent order\n",
    "else:\n",
    "    selected_class_names = all_class_names\n",
    "\n",
    "num_selected_classes = len(selected_class_names)\n",
    "print(f\"Dataset root: {raw_data_path}\")\n",
    "print(f\"Total classes found in raw data: {len(all_class_names)}\")\n",
    "print(f\"Using {num_selected_classes} classes for this analysis: {selected_class_names}\")\n",
    "\n",
    "# Collect file paths and labels\n",
    "filepaths = []\n",
    "labels = []\n",
    "for class_name in selected_class_names:\n",
    "    class_path = raw_data_path / class_name\n",
    "    images = list(class_path.glob('*.[jJ][pP][gG]')) + list(class_path.glob('*.[pP][nN][gG]'))\n",
    "    for img_path in images:\n",
    "        filepaths.append(str(img_path))\n",
    "        labels.append(class_name)\n",
    "\n",
    "print(f\"Total images collected for selected classes: {len(filepaths)}\")\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "print(\"\\nSample of collected data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee42d4d-25f4-4ed8-9031-e147c5fdf9f7",
   "metadata": {},
   "source": [
    "### 2.2. Analyzing Data Distribution & Imbalance\n",
    "\n",
    "We analyze the number of images per class to identify any **class imbalance**. If some diseases have very few images compared to others, our model might become biased. This analysis helps us decide if we need techniques like **Data Augmentation** or **Class Weighting** in the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ee46e-a421-46b6-9841-29cb373580b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot class distribution\n",
    "class_counts = df['label'].value_counts()\n",
    "dist_df = pd.DataFrame({'Class': class_counts.index, 'Count': class_counts.values})\n",
    "dist_df = dist_df.sort_values('Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nClass distribution summary:\")\n",
    "print(dist_df)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.barplot(data=dist_df, x='Count', y='Class', palette='viridis')\n",
    "plt.title('Image Distribution Across Selected Disease Classes', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Number of Images', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Disease Class', fontsize=12, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.FIGURES_DIR / \"eda_class_distribution.png\")\n",
    "plt.show()\n",
    "\n",
    "min_images = dist_df['Count'].min()\n",
    "max_images = dist_df['Count'].max()\n",
    "total_images_in_subset = dist_df['Count'].sum()\n",
    "\n",
    "print(f\"\\nTotal images in selected subset: {total_images_in_subset:,}\")\n",
    "print(f\"Minimum images per class: {min_images}\")\n",
    "print(f\"Maximum images per class: {max_images}\")\n",
    "\n",
    "if max_images / min_images > 2: # Simple heuristic for imbalance\n",
    "    print(\"Observation: Significant class imbalance detected. Strategies like class weighting or oversampling may be needed in subsequent modeling phases.\")\n",
    "else:\n",
    "    print(\"Observation: Classes appear relatively balanced in this subset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e569e3-1b75-4547-8b36-325c9b42f47c",
   "metadata": {},
   "source": [
    "### 2.3. Data Integrity Check\n",
    "\n",
    "To ensure the **FarmAI** training pipeline runs smoothly, we must identify and remove any corrupted or unreadable image files before feeding them into the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6ab76-96db-4808-892c-b956d0c3548f",
   "metadata": {},
   "outputs": [],
   "source": [
    " corrupted_files = []\n",
    "for fpath in df['filepath']:\n",
    "    try:\n",
    "        img = Image.open(fpath)\n",
    "        img.verify() # Verify image integrity\n",
    "    except Exception:\n",
    "        corrupted_files.append(fpath)\n",
    "\n",
    "if corrupted_files:\n",
    "    print(f\"\\nWarning: {len(corrupted_files)} corrupted files found. Examples: {corrupted_files[:5]}\")\n",
    "    # For initial analysis, we'll exclude them. In production, we'd log and handle more gracefully.\n",
    "    df = df[~df['filepath'].isin(corrupted_files)]\n",
    "    print(f\"Removed {len(corrupted_files)} corrupted files. Remaining images: {len(df)}\")\n",
    "else:\n",
    "    print(\"\\n✓ No corrupted image files detected in the selected subset.\")\n",
    "\n",
    "# Save the clean dataframe (with selected classes and no corrupted files)\n",
    "# This DataFrame can be loaded by the next notebook.\n",
    "df.to_csv(config.PROCESSED_DATA_DIR / \"eda_cleaned_data.csv\", index=False)\n",
    "print(f\"✓ Cleaned data information saved to: {config.PROCESSED_DATA_DIR / 'eda_cleaned_data.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31893d24-59cc-4903-988c-7b8d3e39aba3",
   "metadata": {},
   "source": [
    "\n",
    "## 3. EXPLORATORY DATA ANALYSIS (EDA)\n",
    "\n",
    "\n",
    "This section provides visual insights into the image data itself,\n",
    "helping us understand image characteristics and potential challenges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ecbcdb-d191-46b9-b179-842d3d865bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1. Visualize Sample Images\n",
    "\n",
    "## Displaying a few sample images helps in understanding the visual patterns of diseases.\n",
    "\n",
    "\n",
    "# Visualize sample images from selected classes\n",
    "num_sample_images_display = min(5, num_selected_classes) # Display from up to 5 classes\n",
    "sample_classes_for_viz = random.sample(selected_class_names, num_sample_images_display)\n",
    "samples_per_class_viz = 2\n",
    "\n",
    "plt.figure(figsize=(15, 3 * num_sample_images_display))\n",
    "plt.suptitle('Sample Images from Selected Disease Classes (EDA Visuals)', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "for i, class_name in enumerate(sample_classes_for_viz):\n",
    "    # Get filepaths for current class\n",
    "    class_filepaths = df[df['label'] == class_name]['filepath'].tolist()\n",
    "    \n",
    "    # Select random samples\n",
    "    display_samples = random.sample(class_filepaths, min(samples_per_class_viz, len(class_filepaths)))\n",
    "    \n",
    "    for j, img_path_str in enumerate(display_samples):\n",
    "        img = load_img(img_path_str, target_size=config.IMG_SIZE)\n",
    "        \n",
    "        ax = plt.subplot(num_sample_images_display, samples_per_class_viz, i * samples_per_class_viz + j + 1)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        if j == 0:\n",
    "            ax.set_title(f\"{class_name.replace('___', ' ')}\", fontsize=10, fontweight='bold', loc='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.FIGURES_DIR / \"eda_sample_images.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1754f-c63d-4f23-88e2-4e597a7a755f",
   "metadata": {},
   "source": [
    "### 3.2. Strategic Observations for FarmAI Model Development\n",
    "\n",
    "Based on our visual inspection and data analysis, we have established the following roadmap for the FarmAI model:\n",
    "\n",
    "1.  **Image Quality & Consistency:** The dataset contains high-quality, centered leaf images. However, real-world farm photos vary in lighting and angle. To make **FarmAI** robust for farmers, we will implement heavy **Data Augmentation** (rotation, zoom, brightness adjustments) in the next notebook.\n",
    "\n",
    "2.  **Visual Complexity:** Certain diseases (e.g., Early Blight vs. Late Blight) exhibit subtle visual differences. This suggests that a simple CNN might not be enough. We will likely employ **Transfer Learning** using architectures like **EfficientNet** or **MobileNet** to capture these fine-grained features accurately.\n",
    "\n",
    "3.  **Addressing Imbalance:** We observed variations in the image counts across classes. To prevent the model from being biased towards the majority class, we will utilize **Class Weights** during the training process to ensure equitable detection performance across all disease types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3b7e1e-d663-422d-b4ab-c119ac4f6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- DATA INSPECTION & EDA COMPLETE ---\")\n",
    "print(\"Outputs generated:\")\n",
    "print(f\"  - Class Distribution Plot: {config.FIGURES_DIR / 'eda_class_distribution.png'}\")\n",
    "print(f\"  - Sample Images Plot: {config.FIGURES_DIR / 'eda_sample_images.png'}\")\n",
    "print(f\"  - Cleaned Data CSV: {config.PROCESSED_DATA_DIR / 'eda_cleaned_data.csv'}\")\n",
    "print(\"Ready for Preprocessing and Baseline ML.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b7bcb-e084-4053-9424-ae3ddca7cae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381a78e-8471-4c2c-9f34-571a723ec0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (m1env)",
   "language": "python",
   "name": "m1env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
